{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE8aoL4E5f-l",
        "outputId": "acbda34d-73ff-4e4b-a17a-c4dc8c5ec22f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder_path = '/content/drive/My Drive/Capstone/Data/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_path = '/content/drive/My Drive/Capstone/Data/train.xlsx'\n",
        "test_labels_path = '/content/drive/My Drive/Capstone/Data/test.xlsx'\n",
        "val_labels_path = '/content/drive/My Drive/Capstone/Data/validation.xlsx'"
      ],
      "metadata": {
        "id": "FlLVxjF857qA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the label data from the Excel files\n",
        "train_df = pd.read_excel(train_labels_path)\n",
        "test_df = pd.read_excel(test_labels_path)\n",
        "val_df = pd.read_excel(val_labels_path)"
      ],
      "metadata": {
        "id": "t5AkdEZS6pCA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainImg_path = '/content/drive/My Drive/Capstone/TrainTestVal-Images/Train'\n",
        "testImg_path = '/content/drive/My Drive/Capstone/TrainTestVal-Images/Test'\n",
        "valImg_path = '/content/drive/My Drive/Capstone/TrainTestVal-Images/Validation'"
      ],
      "metadata": {
        "id": "SZpt_ZhhLEhU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# # Replace with the path to your zip file\n",
        "# zip_file_path = '/content/drive/My Drive/Capstone/Data/TrainTestVal-Images.zip'\n",
        "\n",
        "# # Replace with the path where you want to extract the contents of the zip file\n",
        "# extract_to_path = '/content/drive/My Drive/Capstone/Data'\n",
        "\n",
        "# # Ensure the extract path exists\n",
        "# if not os.path.exists(extract_to_path):\n",
        "#     os.makedirs(extract_to_path)\n",
        "\n",
        "# # Unzip the file\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_to_path)\n",
        "\n",
        "# print(f\"Extracted all files to {extract_to_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OaHpV0e8LfG-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Replace with the actual path to your images folder\n",
        "images_folder_path = '/content/drive/My Drive/Capstone/Data/TrainTestVal-Images/Validation'\n",
        "\n",
        "# List of image file extensions we're looking for\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp']\n",
        "\n",
        "# Initialize a counter\n",
        "image_count = 0\n",
        "\n",
        "# Walk through all files and folders within the images folder\n",
        "for root, dirs, files in os.walk(images_folder_path):\n",
        "    for file in files:\n",
        "        # Check if the file has one of the image file extensions\n",
        "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "            image_count += 1\n",
        "\n",
        "print(f'The folder contains {image_count} image(s).')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4amZVsCYmSI3",
        "outputId": "3c051b52-9e64-4801-96f7-4345d3b7df91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder contains 23205 image(s).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CUOa00D_q3qa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None):\n",
        "        self.img_labels = pd.read_excel(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
        "      image = Image.open(img_path).convert('RGB')  # Convert image to RGB\n",
        "      label = self.img_labels.iloc[idx, 0]\n",
        "      # Convert the label from string to integer using the mapping dictionary\n",
        "      label = class_to_idx[label]\n",
        "      if self.transform:\n",
        "          image = self.transform(image)\n",
        "      return image, label\n"
      ],
      "metadata": {
        "id": "JkAeEGyeohlQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CustomImageDataset(annotations_file='/content/drive/My Drive/Capstone/Data/train.xlsx',\n",
        "                                   img_dir='/content/drive/My Drive/Capstone/Data/TrainTestVal-Images/Train',\n",
        "                                   transform=transform)\n",
        "\n",
        "test_dataset = CustomImageDataset(annotations_file='/content/drive/My Drive/Capstone/Data/test.xlsx',\n",
        "                                  img_dir='/content/drive/My Drive/Capstone/Data/TrainTestVal-Images/Test',\n",
        "                                  transform=transform)\n",
        "\n",
        "val_dataset = CustomImageDataset(annotations_file='/content/drive/My Drive/Capstone/Data/validation.xlsx',\n",
        "                                 img_dir='/content/drive/My Drive/Capstone/Data/TrainTestVal-Images/Validation',\n",
        "                                 transform=transform)\n"
      ],
      "metadata": {
        "id": "L2c0v5syd8tM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = {class_name: index for index, class_name in enumerate(pd.unique(train_dataset.img_labels['class']))}\n",
        "class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eDTTXjXq9hb",
        "outputId": "be5dac41-c19d-4e3e-bfcb-04bfa95643c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Mass': 0,\n",
              " 'Cardiomegaly': 1,\n",
              " 'Atelectasis': 2,\n",
              " 'Effusion': 3,\n",
              " 'Pneumothorax': 4,\n",
              " 'No Finding': 5,\n",
              " 'Subcutaneous Emphysema': 6,\n",
              " 'Nodule': 7,\n",
              " 'Pleural Thickening': 8,\n",
              " 'Edema': 9,\n",
              " 'Pneumonia': 10,\n",
              " 'Emphysema': 11,\n",
              " 'Infiltration': 12,\n",
              " 'Consolidation': 13,\n",
              " 'Fibrosis': 14}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=128, shuffle=False)\n"
      ],
      "metadata": {
        "id": "4NS_t-3ieSoc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "\n",
        "# Check if GPU is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pretrained ResNet model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "\n",
        "num_classes = 15\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "model = model.to(device)\n",
        "\n",
        "# Summary of the model (optional, it requires torchsummary to be installed)\n",
        "# summary(model, input_size=(3, 224, 224))\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            # Initialize running_corrects as a zero tensor at the start of the epoch\n",
        "            running_corrects = torch.tensor(0, device=device)\n",
        "\n",
        "            # Iterate over data\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                # Use .item() to convert the result of sum to a Python integer and then add to running_corrects tensor\n",
        "                running_corrects += torch.sum(preds == labels.data).item()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects / len(dataloader.dataset)  # Convert to float if necessary\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        print()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model_trained = train_model(model, criterion, optimizer, num_epochs=25)\n",
        "\n",
        "# Save the model (optional)\n",
        "# torch.save(model_trained.state_dict(), 'model_resnet50.pth')\n",
        "\n",
        "# To evaluate on the test set\n",
        "model.eval()\n",
        "# Then loop over your test_loader\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGD39MQQeVUO",
        "outputId": "e4cb4102-b396-42fc-f9e0-4be1646d06b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "----------\n"
          ]
        }
      ]
    }
  ]
}