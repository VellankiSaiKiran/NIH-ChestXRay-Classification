{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea86b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from opencv-python-headless) (1.21.5)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.9.0.80\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e2359a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.4.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.24.4\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.9.0\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Collecting scipy>=1.10.0\n",
      "  Downloading scipy-1.12.0-cp39-cp39-macosx_10_9_x86_64.whl (38.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencv-python-headless>=4.9.0 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (4.9.0.80)\n",
      "Collecting scikit-learn>=1.3.2\n",
      "  Downloading scikit_learn-1.4.1.post1-cp39-cp39-macosx_10_9_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-image>=0.21.0\n",
      "  Downloading scikit_image-0.22.0-cp39-cp39-macosx_10_9_x86_64.whl (13.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (2.8.4)\n",
      "Collecting imageio>=2.27\n",
      "  Downloading imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lazy_loader>=0.3\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (21.3)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (9.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.3.2->albumentations) (2.2.0)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from packaging>=21->scikit-image>=0.21.0->albumentations) (3.0.9)\n",
      "Installing collected packages: typing-extensions, numpy, lazy_loader, joblib, tifffile, scipy, imageio, scikit-learn, scikit-image, albumentations\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: tifffile\n",
      "    Found existing installation: tifffile 2021.7.2\n",
      "    Uninstalling tifffile-2021.7.2:\n",
      "      Successfully uninstalled tifffile-2021.7.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.9.1\n",
      "    Uninstalling scipy-1.9.1:\n",
      "      Successfully uninstalled scipy-1.9.1\n",
      "  Attempting uninstall: imageio\n",
      "    Found existing installation: imageio 2.19.3\n",
      "    Uninstalling imageio-2.19.3:\n",
      "      Successfully uninstalled imageio-2.19.3\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.19.2\n",
      "    Uninstalling scikit-image-0.19.2:\n",
      "      Successfully uninstalled scikit-image-0.19.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed albumentations-1.4.2 imageio-2.34.0 joblib-1.3.2 lazy_loader-0.3 numpy-1.26.4 scikit-image-0.22.0 scikit-learn-1.4.1.post1 scipy-1.12.0 tifffile-2024.2.12 typing-extensions-4.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c9b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia: 1431 images\n",
      "Fibrosis: 1686 images\n",
      "Subcutaneous Emphysema: 1991 images\n",
      "Edema: 2303 images\n",
      "Emphysema: 2516 images\n",
      "Cardiomegaly: 2776 images\n",
      "Pleural Thickening: 3385 images\n",
      "Consolidation: 4667 images\n",
      "Pneumothorax: 5302 images\n",
      "Mass: 5782 images\n",
      "Nodule: 6331 images\n",
      "Atelectasis: 11559 images\n",
      "Effusion: 13317 images\n",
      "Infiltration: 19894 images\n",
      "No Finding: 59406 images\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory where the class-specific folders are saved\n",
    "output_directory = Path('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files')\n",
    "\n",
    "# Dictionary to hold the count of images in each class directory\n",
    "class_image_counts = {}\n",
    "\n",
    "# Iterate over each class directory in the output directory\n",
    "for class_directory in output_directory.iterdir():\n",
    "    if class_directory.is_dir():  # Check if it is a directory\n",
    "        # Count the number of files in the directory\n",
    "        class_image_count = len(list(class_directory.glob('*.*')))\n",
    "        # Add the count to the dictionary\n",
    "        class_image_counts[class_directory.name] = class_image_count\n",
    "\n",
    "# Sort the classes by count\n",
    "sorted_class_image_counts = dict(sorted(class_image_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted counts for each class\n",
    "for class_name, count in sorted_class_image_counts.items():\n",
    "    print(f'{class_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4de6be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:   0%|                                | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Mass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:   6%|█▌                      | 1/16 [00:46<11:34, 46.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Cardiomegaly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  19%|████▌                   | 3/16 [01:54<08:03, 37.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Atelectasis\n",
      "Processing: Effusion\n",
      "Processing: Pneumothorax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders:  44%|██████████▌             | 7/16 [02:45<02:52, 19.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: No Finding\n",
      "Processing: Subcutaneous Emphysema\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  50%|████████████            | 8/16 [03:57<04:16, 32.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Nodule\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  56%|█████████████▌          | 9/16 [04:38<04:01, 34.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Pleural Thickening\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  62%|██████████████▍        | 10/16 [05:43<04:16, 42.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Edema\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  69%|███████████████▊       | 11/16 [06:53<04:11, 50.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Pneumonia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  75%|█████████████████▎     | 12/16 [08:08<03:48, 57.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Emphysema\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  81%|██████████████████▋    | 13/16 [09:17<03:02, 60.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Infiltration\n",
      "Processing: Consolidation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  94%|█████████████████████▌ | 15/16 [10:13<00:45, 45.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Fibrosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders: 100%|███████████████████████| 16/16 [11:25<00:00, 42.87s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from albumentations import (Compose, HorizontalFlip, RandomBrightnessContrast, ShiftScaleRotate, RandomGamma, GaussNoise, PadIfNeeded)\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the augmentation pipeline with safe transformations for chest X-rays\n",
    "aug_pipeline = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    RandomBrightnessContrast(p=0.1, brightness_limit=0.1, contrast_limit=0.1),\n",
    "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "    RandomGamma(gamma_limit=(80, 120), p=0.1),\n",
    "    GaussNoise(var_limit=(10, 50), p=0.1),\n",
    "    PadIfNeeded(min_height=224, min_width=224, p=0.5)  # Padding if needed\n",
    "])\n",
    "\n",
    "\n",
    "def augment_image(file_path, folder_path, augmentation_index):\n",
    "    # Read the image file\n",
    "    image = cv2.imread(file_path)\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # Augment the image\n",
    "    augmented_image = aug_pipeline(image=image)['image']\n",
    "    \n",
    "    # Construct new filename\n",
    "    new_filename = f\"{base_filename}_{augmentation_index}.png\"  # Change the extension if necessary\n",
    "    new_image_path = os.path.join(folder_path, new_filename)\n",
    "    \n",
    "    # Write the augmented image to the disk\n",
    "    cv2.imwrite(new_image_path, augmented_image)\n",
    "    return augmented_image\n",
    "\n",
    "\n",
    "                                \n",
    "def augment_to_target(folder_path, target_count=10000):\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    current_count = len(image_files)\n",
    "    augments_needed = target_count - current_count\n",
    "    \n",
    "    # If we don't need any augmentations, we can return early\n",
    "    if augments_needed <= 0:\n",
    "        return\n",
    "\n",
    "    augmentation_index = 0\n",
    "    while len(os.listdir(folder_path)) < target_count:\n",
    "        # Randomly pick an original image to augment\n",
    "        img_file = np.random.choice(image_files)\n",
    "        file_path = os.path.join(folder_path, img_file)\n",
    "        augment_image(file_path, folder_path, augmentation_index)\n",
    "        augmentation_index += 1\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment'  # Update this to your path\n",
    "\n",
    "# Loop through each subfolder and augment images to reach 10,000 images\n",
    "for subfolder in tqdm(os.listdir(main_folder_path), desc=\"Processing Folders\"):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(f\"Processing: {subfolder}\")\n",
    "        augment_to_target(subfolder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b4df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffdf788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass: 10000 images\n",
      "Cardiomegaly: 10000 images\n",
      "Pneumothorax: 10000 images\n",
      "Subcutaneous Emphysema: 10000 images\n",
      "Nodule: 10000 images\n",
      "Pleural Thickening: 10000 images\n",
      "Edema: 10000 images\n",
      "Pneumonia: 10000 images\n",
      "Emphysema: 10000 images\n",
      "Consolidation: 10000 images\n",
      "Fibrosis: 10000 images\n",
      "Atelectasis: 11559 images\n",
      "Effusion: 13317 images\n",
      "Infiltration: 19894 images\n",
      "No Finding: 59406 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory where the class-specific folders are saved\n",
    "output_directory = Path('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment')\n",
    "\n",
    "# Dictionary to hold the count of images in each class directory\n",
    "class_image_counts = {}\n",
    "\n",
    "# Iterate over each class directory in the output directory\n",
    "for class_directory in output_directory.iterdir():\n",
    "    if class_directory.is_dir():  # Check if it is a directory\n",
    "        # Count the number of files in the directory\n",
    "        class_image_count = len(list(class_directory.glob('*.*')))\n",
    "        # Add the count to the dictionary\n",
    "        class_image_counts[class_directory.name] = class_image_count\n",
    "\n",
    "# Sort the classes by count\n",
    "sorted_class_image_counts = dict(sorted(class_image_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted counts for each class\n",
    "for class_name, count in sorted_class_image_counts.items():\n",
    "    print(f'{class_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b7c4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders: 100%|███████████████████████| 16/16 [00:14<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to reduce the number of images in a folder to 10,000\n",
    "def sample_images(folder_path, target_count=10000):\n",
    "    # List all image files in the folder\n",
    "    images = list(Path(folder_path).glob('*.*'))\n",
    "    \n",
    "    # Shuffle the list of images to ensure random selection\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    # Keep the first 10,000 images, delete the rest\n",
    "    for image in images[target_count:]:\n",
    "        os.remove(image)\n",
    "\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment' \n",
    "\n",
    "# Loop through each subfolder and sample images\n",
    "for subfolder in tqdm(os.listdir(main_folder_path), desc=\"Processing Folders\"):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        sample_images(subfolder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7320fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass: 10000 images\n",
      "Cardiomegaly: 10000 images\n",
      "Atelectasis: 10000 images\n",
      "Effusion: 10000 images\n",
      "Pneumothorax: 10000 images\n",
      "No Finding: 10000 images\n",
      "Subcutaneous Emphysema: 10000 images\n",
      "Nodule: 10000 images\n",
      "Pleural Thickening: 10000 images\n",
      "Edema: 10000 images\n",
      "Pneumonia: 10000 images\n",
      "Emphysema: 10000 images\n",
      "Infiltration: 10000 images\n",
      "Consolidation: 10000 images\n",
      "Fibrosis: 10000 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory where the class-specific folders are saved\n",
    "output_directory = Path('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment')\n",
    "\n",
    "# Dictionary to hold the count of images in each class directory\n",
    "class_image_counts = {}\n",
    "\n",
    "# Iterate over each class directory in the output directory\n",
    "for class_directory in output_directory.iterdir():\n",
    "    if class_directory.is_dir():  # Check if it is a directory\n",
    "        # Count the number of files in the directory\n",
    "        class_image_count = len(list(class_directory.glob('*.*')))\n",
    "        # Add the count to the dictionary\n",
    "        class_image_counts[class_directory.name] = class_image_count\n",
    "\n",
    "# Sort the classes by count\n",
    "sorted_class_image_counts = dict(sorted(class_image_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted counts for each class\n",
    "for class_name, count in sorted_class_image_counts.items():\n",
    "    print(f'{class_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cf01c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (1.4.4)\n",
      "Requirement already satisfied: openpyxl in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (3.0.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: et_xmlfile in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9226889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment'\n",
    "\n",
    "\n",
    "# Prepare a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each subfolder and collect image names\n",
    "for subfolder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get all image files in the folder\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        # Add the folder name and image file name to the data list\n",
    "        for image_file in image_files:\n",
    "            data.append({'Folder Name': subfolder_name, 'Image File Name': image_file})\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the path for the Excel file to be saved\n",
    "excel_path = os.path.join(main_folder_path, 'ImageData.xlsx')\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel(excel_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d5a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/ImageData.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78e5f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder Name</th>\n",
       "      <th>Image File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00014105_001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00013285_013_3581.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00005785_000_2597.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00016778_022.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00019369_002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>Fibrosis</td>\n",
       "      <td>00006043_000_3247.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>Fibrosis</td>\n",
       "      <td>00003098_012_5153.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>Fibrosis</td>\n",
       "      <td>00000149_007_5731.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>Fibrosis</td>\n",
       "      <td>00003834_001_6861.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>Fibrosis</td>\n",
       "      <td>00016684_000_1504.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Folder Name        Image File Name\n",
       "0             Mass       00014105_001.png\n",
       "1             Mass  00013285_013_3581.png\n",
       "2             Mass  00005785_000_2597.png\n",
       "3             Mass       00016778_022.png\n",
       "4             Mass       00019369_002.png\n",
       "...            ...                    ...\n",
       "149995    Fibrosis  00006043_000_3247.png\n",
       "149996    Fibrosis  00003098_012_5153.png\n",
       "149997    Fibrosis  00000149_007_5731.png\n",
       "149998    Fibrosis  00003834_001_6861.png\n",
       "149999    Fibrosis  00016684_000_1504.png\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b89567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Folder Name, Image File Name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicates = df[df.duplicated(['Folder Name', 'Image File Name'], keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0caa79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the paths to the main directory and the train and test directories\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment'\n",
    "train_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment'\n",
    "test_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment'\n",
    "\n",
    "# Ensure the train and test folders exist\n",
    "os.makedirs(train_folder_path, exist_ok=True)\n",
    "os.makedirs(test_folder_path, exist_ok=True)\n",
    "\n",
    "# Go through each folder and randomly select 80% for training and the rest for testing\n",
    "for folder_name in os.listdir(main_folder_path):\n",
    "    folder_path = os.path.join(main_folder_path, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        # List all image files\n",
    "        images = os.listdir(folder_path)\n",
    "        # Split the images into train and test sets\n",
    "        train_images, test_images = train_test_split(images, train_size=0.8, random_state=42)\n",
    "        \n",
    "        # Create and populate the train folder\n",
    "        train_subfolder_path = os.path.join(train_folder_path, f'{folder_name}_train')\n",
    "        os.makedirs(train_subfolder_path, exist_ok=True)\n",
    "        for image_file in train_images:\n",
    "            src_path = os.path.join(folder_path, image_file)\n",
    "            dst_path = os.path.join(train_subfolder_path, image_file)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "        \n",
    "        # Create and populate the test folder\n",
    "        test_subfolder_path = os.path.join(test_folder_path, f'{folder_name}_test')\n",
    "        os.makedirs(test_subfolder_path, exist_ok=True)\n",
    "        for image_file in test_images:\n",
    "            src_path = os.path.join(folder_path, image_file)\n",
    "            dst_path = os.path.join(test_subfolder_path, image_file)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8612a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Base directory where the '_train' folders are located\n",
    "base_train_dir = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/Train'\n",
    "\n",
    "# New base directory for '_validation' folders\n",
    "base_validation_dir = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/Train'\n",
    "os.makedirs(base_validation_dir, exist_ok=True)\n",
    "\n",
    "# Split ratio for validation set\n",
    "validation_split = 0.2\n",
    "\n",
    "# Process each '_train' folder to split off a validation set\n",
    "for folder_name in os.listdir(base_train_dir):\n",
    "    if folder_name.endswith('_train'):\n",
    "        folder_path = os.path.join(base_train_dir, folder_name)\n",
    "        images = os.listdir(folder_path)\n",
    "        \n",
    "        # Split the images into train and validation sets\n",
    "        _, validation_images = train_test_split(images, test_size=validation_split, random_state=42)\n",
    "        \n",
    "        # Create a new corresponding '_validation' folder\n",
    "        validation_folder_name = folder_name.replace('_train', '_validation')\n",
    "        validation_folder_path = os.path.join(base_validation_dir, validation_folder_name)\n",
    "        os.makedirs(validation_folder_path, exist_ok=True)\n",
    "        \n",
    "        # Move the selected validation images to the new validation folder\n",
    "        for image in validation_images:\n",
    "            src_path = os.path.join(folder_path, image)\n",
    "            dst_path = os.path.join(validation_folder_path, image)\n",
    "            shutil.move(src_path, dst_path)  # Use move to transfer files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd875b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumothorax_test: 2000 images\n",
      "Consolidation_test: 2000 images\n",
      "Fibrosis_test: 2000 images\n",
      "Effusion_test: 2000 images\n",
      "Mass_test: 2000 images\n",
      "Pneumonia_test: 2000 images\n",
      "Atelectasis_test: 2000 images\n",
      "Infiltration_test: 2000 images\n",
      "Subcutaneous Emphysema_test: 2000 images\n",
      "Edema_test: 2000 images\n",
      "Pleural Thickening_test: 2000 images\n",
      "Nodule_test: 2000 images\n",
      "Emphysema_test: 2000 images\n",
      "No Finding_test: 2000 images\n",
      "Cardiomegaly_test: 2000 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory where the class-specific folders are saved\n",
    "output_directory = Path('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/Test')\n",
    "\n",
    "# Dictionary to hold the count of images in each class directory\n",
    "class_image_counts = {}\n",
    "\n",
    "# Iterate over each class directory in the output directory\n",
    "for class_directory in output_directory.iterdir():\n",
    "    if class_directory.is_dir():  # Check if it is a directory\n",
    "        # Count the number of files in the directory\n",
    "        class_image_count = len(list(class_directory.glob('*.*')))\n",
    "        # Add the count to the dictionary\n",
    "        class_image_counts[class_directory.name] = class_image_count\n",
    "\n",
    "# Sort the classes by count\n",
    "sorted_class_image_counts = dict(sorted(class_image_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted counts for each class\n",
    "for class_name, count in sorted_class_image_counts.items():\n",
    "    print(f'{class_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "988e3ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the main folder containing all subfolders\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/Train'  # Change this to your main folder path\n",
    "\n",
    "# Prepare a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each subfolder and collect image names\n",
    "for subfolder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get all image files in the folder\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        # Add the folder name and image file name to the data list\n",
    "        for image_file in image_files:\n",
    "            data.append({'class': subfolder_name, 'image': image_file})\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the path for the Excel file to be saved\n",
    "excel_path = os.path.join(main_folder_path, 'train_data.xlsx')\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel(excel_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b35a9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the main folder containing all subfolders\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/Test'  # Change this to your main folder path\n",
    "\n",
    "# Prepare a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each subfolder and collect image names\n",
    "for subfolder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get all image files in the folder\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        # Add the folder name and image file name to the data list\n",
    "        for image_file in image_files:\n",
    "            data.append({'class': subfolder_name, 'image': image_file})\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the path for the Excel file to be saved\n",
    "excel_path = os.path.join(main_folder_path, 'test_data.xlsx')\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dd40240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the main folder containing all subfolders\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/Validation'  # Change this to your main folder path\n",
    "\n",
    "# Prepare a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each subfolder and collect image names\n",
    "for subfolder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get all image files in the folder\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        # Add the folder name and image file name to the data list\n",
    "        for image_file in image_files:\n",
    "            data.append({'class': subfolder_name, 'image': image_file})\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the path for the Excel file to be saved\n",
    "excel_path = os.path.join(main_folder_path, 'validation_data.xlsx')\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2278f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [class, image]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_excel('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/train_data.xlsx')\n",
    "\n",
    "duplicates = train[train.duplicated(['class', 'image'], keep=False)]\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "210ef442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [class, image]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_excel('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/test_data.xlsx')\n",
    "\n",
    "duplicates = test[test.duplicated(['class', 'image'], keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bb87b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [class, image]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "val = pd.read_excel('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Files-to-augment/validation_data.xlsx')\n",
    "\n",
    "duplicates = val[val.duplicated(['class', 'image'], keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "876cf39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass                      1600\n",
      "Cardiomegaly              1600\n",
      "Atelectasis               1600\n",
      "Effusion                  1600\n",
      "Pneumothorax              1600\n",
      "No Finding                1600\n",
      "Subcutaneous Emphysema    1600\n",
      "Nodule                    1600\n",
      "Pleural Thickening        1600\n",
      "Edema                     1600\n",
      "Pneumonia                 1600\n",
      "Emphysema                 1600\n",
      "Infiltration              1600\n",
      "Consolidation             1600\n",
      "Fibrosis                  1600\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "image_counts = val['class'].value_counts()\n",
    "print(image_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad5c546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
