{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea86b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e2359a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (1.4.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (4.10.0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (1.12.0)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (0.22.0)\n",
      "Requirement already satisfied: PyYAML in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (1.4.1.post1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (4.9.0.80)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (2024.2.12)\n",
      "Requirement already satisfied: imageio>=2.27 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (2.34.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (2.8.4)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (9.2.0)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (0.3)\n",
      "Requirement already satisfied: packaging>=21 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.21.0->albumentations) (21.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.3.2->albumentations) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.3.2->albumentations) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from packaging>=21->scikit-image>=0.21.0->albumentations) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd49c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/filtered_images.csv'  # Replace with the path to your CSV file\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# List of disease folders to delete\n",
    "diseases_to_delete = [\n",
    "    'Emphysema', 'Edema', 'Subcutaneous Emphysema', 'Fibrosis',\n",
    "    'Pneumonia', 'Tortuous Aorta', 'Calcification of the Aorta',\n",
    "    'Pneumoperitoneum', 'Pneumomediastinum', 'Hernia'\n",
    "]\n",
    "\n",
    "# Root directory where the disease folders are located\n",
    "root_directory = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images'  # Replace with the path to your folders\n",
    "\n",
    "# Delete the specified folders and their contents\n",
    "for disease in diseases_to_delete:\n",
    "    folder_path = os.path.join(root_directory, disease)\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Deleted folder: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"Folder not found, skipped: {folder_path}\")\n",
    "\n",
    "# Assuming df is your DataFrame and it contains a column 'disease' that matches the folder names\n",
    "# If the disease names are not an exact match, you will need to adjust the filtering accordingly\n",
    "\n",
    "\n",
    "# Filter out the rows for each of the diseases to delete\n",
    "for disease in diseases_to_delete:\n",
    "    df = df[df[disease] != 1]  # Filtering rows where disease column is not equal to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7038d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns corresponding to the deleted diseases\n",
    "df_dropped = df.drop(columns=diseases_to_delete, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259888ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save the updated DataFrame to a CSV file\n",
    "updated_csv_file_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/final10.csv'  # Replace with your desired path\n",
    "df_dropped.to_csv(updated_csv_file_path, index=False)\n",
    "\n",
    "print(f\"Updated DataFrame saved to {updated_csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b9760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514d599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory where the class-specific folders are saved\n",
    "output_directory = Path('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images')\n",
    "\n",
    "# Dictionary to hold the count of images in each class directory\n",
    "class_image_counts = {}\n",
    "\n",
    "# Iterate over each class directory in the output directory\n",
    "for class_directory in output_directory.iterdir():\n",
    "    if class_directory.is_dir():  # Check if it is a directory\n",
    "        # Count the number of files in the directory\n",
    "        class_image_count = len(list(class_directory.glob('*.*')))\n",
    "        # Add the count to the dictionary\n",
    "        class_image_counts[class_directory.name] = class_image_count\n",
    "\n",
    "# Sort the classes by count\n",
    "sorted_class_image_counts = dict(sorted(class_image_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted counts for each class\n",
    "for class_name, count in sorted_class_image_counts.items():\n",
    "    print(f'{class_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_directory = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images'  # Replace with the path to your folders\n",
    "\n",
    "# Supported image file extensions\n",
    "image_extensions = {'.jpg', '.jpeg', '.png', '.gif'}\n",
    "\n",
    "# Initialize a counter\n",
    "total_images = 0\n",
    "\n",
    "# Walk through all directories and files in the root directory\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    # Count only files with supported image extensions\n",
    "    total_images += sum(file.endswith(ext) for file in files for ext in image_extensions)\n",
    "\n",
    "print(f\"Total number of images in all folders: {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b6b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4de6be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:   0%|                                | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Mass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:   9%|██▏                     | 1/11 [01:12<12:02, 72.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Cardiomegaly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  27%|██████▌                 | 3/11 [02:27<06:11, 46.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Atelectasis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  36%|████████▋               | 4/11 [03:27<05:59, 51.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Effusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  45%|██████████▉             | 5/11 [04:29<05:28, 54.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Pneumothorax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  55%|█████████████           | 6/11 [05:41<05:01, 60.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: No Finding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  64%|███████████████▎        | 7/11 [05:41<02:45, 41.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Nodule\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  73%|█████████████████▍      | 8/11 [06:51<02:31, 50.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Pleural Thickening\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  82%|███████████████████▋    | 9/11 [08:09<01:57, 58.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Infiltration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Folders:  91%|████████████████████▉  | 10/11 [08:16<00:42, 42.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Consolidation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders: 100%|███████████████████████| 11/11 [09:31<00:00, 51.93s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast, ShiftScaleRotate, RandomGamma, GaussNoise, PadIfNeeded, ElasticTransform, CLAHE, RandomCrop\n",
    "          \n",
    "aug_pipeline = Compose([\n",
    "    HorizontalFlip(p=0.5),  # Flips the image horizontally with a 50% chance, useful for simulating patient orientation variations.\n",
    "    RandomBrightnessContrast(p=0.1, brightness_limit=0.1, contrast_limit=0.1),  # Subtly adjusts brightness/contrast to mimic exposure variations without obscuring details.\n",
    "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),  # Slightly shifts, scales, and rotates images to simulate patient movement and positioning, avoiding extreme distortions.\n",
    "    RandomGamma(gamma_limit=(80, 120), p=0.1),  # Adjusts the gamma to introduce variations in image brightness akin to different acquisition settings, ensuring the changes remain realistic.\n",
    "    GaussNoise(var_limit=(10, 50), p=0.1),  # Adds Gaussian noise to simulate electronic noise in X-ray acquisition, with a careful limit to prevent artificial appearance.\n",
    "    CLAHE(clip_limit=2, tile_grid_size=(8, 8), p=0.2),  # Enhances local contrast in a way that is adaptive to different regions of the image, improving visibility of important features without overemphasizing noise.\n",
    "])\n",
    "\n",
    "def augment_image(file_path, folder_path, augmentation_index):\n",
    "    # Read the image file\n",
    "    image = cv2.imread(file_path)\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # Augment the image\n",
    "    augmented_image = aug_pipeline(image=image)['image']\n",
    "    \n",
    "    # Construct new filename\n",
    "    new_filename = f\"{base_filename}_{augmentation_index}.png\"  # Change the extension if necessary\n",
    "    new_image_path = os.path.join(folder_path, new_filename)\n",
    "    \n",
    "    # Write the augmented image to the disk\n",
    "    cv2.imwrite(new_image_path, augmented_image)\n",
    "    return augmented_image\n",
    "\n",
    "\n",
    "                                \n",
    "def augment_to_target(folder_path, target_count=10000):\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    current_count = len(image_files)\n",
    "    augments_needed = target_count - current_count\n",
    "    \n",
    "    # If we don't need any augmentations, we can return early\n",
    "    if augments_needed <= 0:\n",
    "        return\n",
    "\n",
    "    augmentation_index = 0\n",
    "    while len(os.listdir(folder_path)) < target_count:\n",
    "        # Randomly pick an original image to augment\n",
    "        img_file = np.random.choice(image_files)\n",
    "        file_path = os.path.join(folder_path, img_file)\n",
    "        augment_image(file_path, folder_path, augmentation_index)\n",
    "        augmentation_index += 1\n",
    "                \n",
    "\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images'  # Update this to your path\n",
    "\n",
    "# Loop through each subfolder and augment images to reach 10,000 images\n",
    "for subfolder in tqdm(os.listdir(main_folder_path), desc=\"Processing Folders\"):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(f\"Processing: {subfolder}\")\n",
    "        augment_to_target(subfolder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2b4df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass: 10000 images\n",
      "Cardiomegaly: 10000 images\n",
      "Atelectasis: 10000 images\n",
      "Effusion: 10000 images\n",
      "Pneumothorax: 10000 images\n",
      "Nodule: 10000 images\n",
      "Pleural Thickening: 10000 images\n",
      "Infiltration: 10000 images\n",
      "Consolidation: 10000 images\n",
      "No Finding: 59406 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory where the class-specific folders are saved\n",
    "output_directory = Path('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images')\n",
    "\n",
    "# Dictionary to hold the count of images in each class directory\n",
    "class_image_counts = {}\n",
    "\n",
    "# Iterate over each class directory in the output directory\n",
    "for class_directory in output_directory.iterdir():\n",
    "    if class_directory.is_dir():  # Check if it is a directory\n",
    "        # Count the number of files in the directory\n",
    "        class_image_count = len(list(class_directory.glob('*.*')))\n",
    "        # Add the count to the dictionary\n",
    "        class_image_counts[class_directory.name] = class_image_count\n",
    "\n",
    "# Sort the classes by count\n",
    "sorted_class_image_counts = dict(sorted(class_image_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted counts for each class\n",
    "for class_name, count in sorted_class_image_counts.items():\n",
    "    print(f'{class_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b2f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4162d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffdf788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass: 10000 images\n",
      "Cardiomegaly: 10000 images\n",
      "Atelectasis: 10000 images\n",
      "Effusion: 10000 images\n",
      "Pneumothorax: 10000 images\n",
      "Nodule: 10000 images\n",
      "Pleural Thickening: 10000 images\n",
      "Infiltration: 10000 images\n",
      "Consolidation: 10000 images\n",
      "No Finding: 59406 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory where the class-specific folders are saved\n",
    "output_directory = Path('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images')\n",
    "\n",
    "# Dictionary to hold the count of images in each class directory\n",
    "class_image_counts = {}\n",
    "\n",
    "# Iterate over each class directory in the output directory\n",
    "for class_directory in output_directory.iterdir():\n",
    "    if class_directory.is_dir():  # Check if it is a directory\n",
    "        # Count the number of files in the directory\n",
    "        class_image_count = len(list(class_directory.glob('*.*')))\n",
    "        # Add the count to the dictionary\n",
    "        class_image_counts[class_directory.name] = class_image_count\n",
    "\n",
    "# Sort the classes by count\n",
    "sorted_class_image_counts = dict(sorted(class_image_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted counts for each class\n",
    "for class_name, count in sorted_class_image_counts.items():\n",
    "    print(f'{class_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7c4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders: 100%|███████████████████████| 11/11 [00:12<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to reduce the number of images in a folder to 10,000\n",
    "def sample_images(folder_path, target_count=10000):\n",
    "    # List all image files in the folder\n",
    "    images = list(Path(folder_path).glob('*.*'))\n",
    "    \n",
    "    # Shuffle the list of images to ensure random selection\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    # Keep the first 10,000 images, delete the rest\n",
    "    for image in images[target_count:]:\n",
    "        os.remove(image)\n",
    "\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images' \n",
    "\n",
    "# Loop through each subfolder and sample images\n",
    "for subfolder in tqdm(os.listdir(main_folder_path), desc=\"Processing Folders\"):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        sample_images(subfolder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7320fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mass: 10000 images\n",
      "Cardiomegaly: 10000 images\n",
      "Atelectasis: 10000 images\n",
      "Effusion: 10000 images\n",
      "Pneumothorax: 10000 images\n",
      "No Finding: 10000 images\n",
      "Nodule: 10000 images\n",
      "Pleural Thickening: 10000 images\n",
      "Infiltration: 10000 images\n",
      "Consolidation: 10000 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory where the class-specific folders are saved\n",
    "output_directory = Path('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images')\n",
    "\n",
    "# Dictionary to hold the count of images in each class directory\n",
    "class_image_counts = {}\n",
    "\n",
    "# Iterate over each class directory in the output directory\n",
    "for class_directory in output_directory.iterdir():\n",
    "    if class_directory.is_dir():  # Check if it is a directory\n",
    "        # Count the number of files in the directory\n",
    "        class_image_count = len(list(class_directory.glob('*.*')))\n",
    "        # Add the count to the dictionary\n",
    "        class_image_counts[class_directory.name] = class_image_count\n",
    "\n",
    "# Sort the classes by count\n",
    "sorted_class_image_counts = dict(sorted(class_image_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted counts for each class\n",
    "for class_name, count in sorted_class_image_counts.items():\n",
    "    print(f'{class_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25cf01c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (1.4.4)\n",
      "Requirement already satisfied: openpyxl in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (3.0.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: et_xmlfile in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saikiranreddyvellanki/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9226889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images'\n",
    "\n",
    "\n",
    "# Prepare a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each subfolder and collect image names\n",
    "for subfolder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get all image files in the folder\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        # Add the folder name and image file name to the data list\n",
    "        for image_file in image_files:\n",
    "            data.append({'Folder Name': subfolder_name, 'Image File Name': image_file})\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the path for the Excel file to be saved\n",
    "excel_path = os.path.join(main_folder_path, 'AugmentExcel.xlsx')\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel(excel_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d5a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('/Users/saikiranreddyvellanki/Documents/CapstoneProject/AugmentExcel.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f78e5f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder Name</th>\n",
       "      <th>Image File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00014105_001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00016778_022.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00019369_002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00012342_003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mass</td>\n",
       "      <td>00018663_002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>00008397_003_723.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>00010805_002_8557.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>00016729_002_1396.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>00013310_011_7883.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>00007437_000_8130.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Folder Name        Image File Name\n",
       "0               Mass       00014105_001.png\n",
       "1               Mass       00016778_022.png\n",
       "2               Mass       00019369_002.png\n",
       "3               Mass       00012342_003.png\n",
       "4               Mass       00018663_002.png\n",
       "...              ...                    ...\n",
       "99995  Consolidation   00008397_003_723.png\n",
       "99996  Consolidation  00010805_002_8557.png\n",
       "99997  Consolidation  00016729_002_1396.png\n",
       "99998  Consolidation  00013310_011_7883.png\n",
       "99999  Consolidation  00007437_000_8130.png\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b89567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Folder Name, Image File Name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicates = df[df.duplicated(['Folder Name', 'Image File Name'], keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0caa79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the paths to the main directory and the train and test directories\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images'\n",
    "train_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images'\n",
    "test_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images'\n",
    "\n",
    "# Ensure the train and test folders exist\n",
    "os.makedirs(train_folder_path, exist_ok=True)\n",
    "os.makedirs(test_folder_path, exist_ok=True)\n",
    "\n",
    "# Go through each folder and randomly select 80% for training and the rest for testing\n",
    "for folder_name in os.listdir(main_folder_path):\n",
    "    folder_path = os.path.join(main_folder_path, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        # List all image files\n",
    "        images = os.listdir(folder_path)\n",
    "        # Split the images into train and test sets\n",
    "        train_images, test_images = train_test_split(images, train_size=0.8, random_state=42)\n",
    "        \n",
    "        # Create and populate the train folder\n",
    "        train_subfolder_path = os.path.join(train_folder_path, f'{folder_name}_train')\n",
    "        os.makedirs(train_subfolder_path, exist_ok=True)\n",
    "        for image_file in train_images:\n",
    "            src_path = os.path.join(folder_path, image_file)\n",
    "            dst_path = os.path.join(train_subfolder_path, image_file)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "        \n",
    "        # Create and populate the test folder\n",
    "        test_subfolder_path = os.path.join(test_folder_path, f'{folder_name}_test')\n",
    "        os.makedirs(test_subfolder_path, exist_ok=True)\n",
    "        for image_file in test_images:\n",
    "            src_path = os.path.join(folder_path, image_file)\n",
    "            dst_path = os.path.join(test_subfolder_path, image_file)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8612a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Base directory where the '_train' folders are located\n",
    "base_train_dir = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images/Train'\n",
    "\n",
    "# New base directory for '_validation' folders\n",
    "base_validation_dir = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images/Train'\n",
    "os.makedirs(base_validation_dir, exist_ok=True)\n",
    "\n",
    "# Split ratio for validation set\n",
    "validation_split = 0.2\n",
    "\n",
    "# Process each '_train' folder to split off a validation set\n",
    "for folder_name in os.listdir(base_train_dir):\n",
    "    if folder_name.endswith('_train'):\n",
    "        folder_path = os.path.join(base_train_dir, folder_name)\n",
    "        images = os.listdir(folder_path)\n",
    "        \n",
    "        # Split the images into train and validation sets\n",
    "        _, validation_images = train_test_split(images, test_size=validation_split, random_state=42)\n",
    "        \n",
    "        # Create a new corresponding '_validation' folder\n",
    "        validation_folder_name = folder_name.replace('_train', '_validation')\n",
    "        validation_folder_path = os.path.join(base_validation_dir, validation_folder_name)\n",
    "        os.makedirs(validation_folder_path, exist_ok=True)\n",
    "        \n",
    "        # Move the selected validation images to the new validation folder\n",
    "        for image in validation_images:\n",
    "            src_path = os.path.join(folder_path, image)\n",
    "            dst_path = os.path.join(validation_folder_path, image)\n",
    "            shutil.move(src_path, dst_path)  # Use move to transfer files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd875b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumothorax_test: 2000 images\n",
      "Consolidation_test: 2000 images\n",
      "Effusion_test: 2000 images\n",
      "Mass_test: 2000 images\n",
      "Atelectasis_test: 2000 images\n",
      "Infiltration_test: 2000 images\n",
      "Pleural Thickening_test: 2000 images\n",
      "Nodule_test: 2000 images\n",
      "No Finding_test: 2000 images\n",
      "Cardiomegaly_test: 2000 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory where the class-specific folders are saved\n",
    "output_directory = Path('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images/Test')\n",
    "\n",
    "# Dictionary to hold the count of images in each class directory\n",
    "class_image_counts = {}\n",
    "\n",
    "# Iterate over each class directory in the output directory\n",
    "for class_directory in output_directory.iterdir():\n",
    "    if class_directory.is_dir():  # Check if it is a directory\n",
    "        # Count the number of files in the directory\n",
    "        class_image_count = len(list(class_directory.glob('*.*')))\n",
    "        # Add the count to the dictionary\n",
    "        class_image_counts[class_directory.name] = class_image_count\n",
    "\n",
    "# Sort the classes by count\n",
    "sorted_class_image_counts = dict(sorted(class_image_counts.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted counts for each class\n",
    "for class_name, count in sorted_class_image_counts.items():\n",
    "    print(f'{class_name}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "988e3ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the main folder containing all subfolders\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images/Train'  # Change this to your main folder path\n",
    "\n",
    "# Prepare a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each subfolder and collect image names\n",
    "for subfolder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get all image files in the folder\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        # Add the folder name and image file name to the data list\n",
    "        for image_file in image_files:\n",
    "            data.append({'class': subfolder_name, 'image': image_file})\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the path for the Excel file to be saved\n",
    "excel_path = os.path.join(main_folder_path, 'train_data.xlsx')\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel(excel_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b35a9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the main folder containing all subfolders\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images/Test'  # Change this to your main folder path\n",
    "\n",
    "# Prepare a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each subfolder and collect image names\n",
    "for subfolder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get all image files in the folder\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        # Add the folder name and image file name to the data list\n",
    "        for image_file in image_files:\n",
    "            data.append({'class': subfolder_name, 'image': image_file})\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the path for the Excel file to be saved\n",
    "excel_path = os.path.join(main_folder_path, 'test_data.xlsx')\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dd40240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the main folder containing all subfolders\n",
    "main_folder_path = '/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images/Validation'  # Change this to your main folder path\n",
    "\n",
    "# Prepare a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each subfolder and collect image names\n",
    "for subfolder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get all image files in the folder\n",
    "        image_files = os.listdir(subfolder_path)\n",
    "        # Add the folder name and image file name to the data list\n",
    "        for image_file in image_files:\n",
    "            data.append({'class': subfolder_name, 'image': image_file})\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the path for the Excel file to be saved\n",
    "excel_path = os.path.join(main_folder_path, 'validation_data.xlsx')\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2278f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [class, image]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_excel('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images/train_data.xlsx')\n",
    "\n",
    "duplicates = train[train.duplicated(['class', 'image'], keep=False)]\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "210ef442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [class, image]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_excel('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images/test_data.xlsx')\n",
    "\n",
    "duplicates = test[test.duplicated(['class', 'image'], keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb87b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [class, image]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "val = pd.read_excel('/Users/saikiranreddyvellanki/Documents/CapstoneProject/Images/validation_data.xlsx')\n",
    "\n",
    "duplicates = val[val.duplicated(['class', 'image'], keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "876cf39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumothorax_test          2000\n",
      "Consolidation_test         2000\n",
      "Effusion_test              2000\n",
      "Mass_test                  2000\n",
      "Atelectasis_test           2000\n",
      "Infiltration_test          2000\n",
      "Pleural Thickening_test    2000\n",
      "Nodule_test                2000\n",
      "No Finding_test            2000\n",
      "Cardiomegaly_test          2000\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "image_counts = train['class'].value_counts()\n",
    "print(image_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c848328",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_counts = test['class'].value_counts()\n",
    "print(image_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bad5c546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidation_validation         1600\n",
      "Effusion_validation              1600\n",
      "Infiltration_validation          1600\n",
      "Nodule_validation                1600\n",
      "Cardiomegaly_validation          1600\n",
      "Pleural Thickening_validation    1600\n",
      "No Finding_validation            1600\n",
      "Mass_validation                  1600\n",
      "Atelectasis_validation           1600\n",
      "Pneumothorax_validation          1600\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "image_counts = val['class'].value_counts()\n",
    "print(image_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009851b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
